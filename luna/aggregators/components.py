from luna.datatypes.dimensional import TimePoint, TimeSlot
from luna.datatypes.composite import DataTimePoint, DataTimeSlot, PhysicalData, DataTimeSeries, DataPoint, DataSlot
from luna.datatypes.auxiliary import PhysicalQuantity
from luna.common.exceptions import ConsistencyException, ConfigurationException
from luna.aggregators.utilities import compute_coverage
import sys

#--------------------------
#    Logger
#--------------------------

import logging
logger = logging.getLogger(__name__)


#-------------------------------------
# Aggregators
#-------------------------------------

# An Aggregator processes some data (DataPoints or DataSlots) encapsulated in a
# Set(DataSet/Series/DataSeries/DataTimeSeries) and return a Region/Slot.
# The operation that the aggregator will perform are defined in the Sensor object,
# and in particular in all its extensions. See the sensors package for more info.

class Aggregator(object):
    '''Base Aggregator class'''
    pass

# Should be: PhysicalDataTimePointsAggregator ( and PhysicalDataTimeSeries)
 
 

class DataTimePointsAggregator(Aggregator):
    '''Aggregate DataTimePoints of a DataTimeSeries into a DataTimeSlot
    The Aggregator is STATELESS'''
    
    # TODO: Merge me into a DataTimeSeriesAggregator, using the data type to understand how to aggregate? 
 
    def __init__(self, Sensor):
        self.Sensor = Sensor
    
    def aggregate(self, dataTimeSeries, start_dt, end_dt, timeSlotSpan, prev_dataTimePoint, next_dataTimePoint):

        #-------------------
        # Sanity checks
        #-------------------

        # First of all Ensure we are operating on PhysicalData (so we eill have PhysicalQuantities),
        # otherwise raise an error:
        if self.Sensor.Points_type.data_type != PhysicalData:
            raise NotImplementedError('Sorry, only PhysicalData data type is supported for now. Adding support for generic data is not too much complicated anyway')


        #-------------------
        # Support vars
        #-------------------
        Slot_data_labels_to_generate = self.Sensor.Slots_data_labels
        Slot_data_labels             = []
        Slot_data_vaues              = []
        Slot_coverage                = None
        Slot_physicalData            = None

        #-------------------
        # Compute coverage
        #-------------------
        Slot_coverage = compute_coverage(dataTimeSeries, start_dt, end_dt, prev_dataTimePoint, next_dataTimePoint)

        #--------------------------------------------
        # Understand the labels to produce and to 
        # operate on according to the sensor type
        #--------------------------------------------
        


        for Slot_data_label_to_generate in Slot_data_labels_to_generate:
            
            handled      = False
            Generator    = None
            Operation    = None
            operate_on  = None
            
            # Labels could already be PhysicalQuantiy objects
            if not isinstance(Slot_data_label_to_generate, PhysicalQuantity):
                physicalQuantity = PhysicalQuantity(Slot_data_label_to_generate)
            
            # Is this physicalQuantity generated by a custom generator defined inside the sensor class? 
            try:
                # TODO: Use the 'provides' logic
                Generator = getattr(self.Sensor, Slot_data_label_to_generate)
                operate_on =  Generator.depends
                handled = True
            except AttributeError:
                pass
            
            # Is this physicalQuantity generated by a standard generator?
            try:
                from luna.aggregators import generators
                Generator = getattr(generators, Slot_data_label_to_generate)
                operate_on =  Generator.depends
                handled = True
            except AttributeError:
                pass
            
            # Is this physicalQuantity generated  by applying the operation to another physicalQuantity,
            # defined in the Points?
            for Point_physicalQuantity in self.Sensor.Points_data_labels:
                if physicalQuantity.name_unit == Point_physicalQuantity:
                    try:
                        from luna.aggregators import operations
                        Operation = getattr(operations, physicalQuantity.op)
                    except AttributeError:
                        # TODO: add more info (i.e. sensor class etc?)
                        raise ConfigurationException('Sorry, I cannot find any valid operation for {} in luna.aggregators.operations'.format(physicalQuantity.op))
    
                    operate_on = Point_physicalQuantity
                    handled = True
                    break

            if not handled:
                # TODO: add more info (i.e. sensor class etc?)
                raise ConfigurationException('Could not handle "{}", as I did not find any way to generate it. Please check your configuration for this sensor'.format(Slot_data_label_to_generate))
            
            # TODO: Understand how to compute the missing Points
            # TODO: Understand how to compute the missing  stuff (?)
    
            #----------------------
            # Compute
            #----------------------
            
            if Generator:
                
                logger.debug('Running generator %s on %s to generate %s', Generator, operate_on, Slot_data_label_to_generate)

                # A generator also requires access to the aggregated data, so we initialize it also here* *
                Slot_physicalData = self.Sensor.Points_type.data_type(labels = Slot_data_labels,
                                                                      values = Slot_data_vaues)
                # Run the generator
                result = Generator.generate(dataTimeSeries     = dataTimeSeries,
                                            aggregated_data    = Slot_physicalData,
                                            prev_dataTimePoint = prev_dataTimePoint,
                                            next_dataTimePoint = next_dataTimePoint,
                                            start_dt           = start_dt,
                                            end_dt             = end_dt)

            elif Operation:
                
                logger.debug('Running operation %s on %s to generate %s', Operation, operate_on, Slot_data_label_to_generate)
                
                # Run the operation
                result = Operation.compute_on_Points(dataTimeSeries     = dataTimeSeries,
                                                     operate_on         = operate_on,
                                                     prev_dataTimePoint = prev_dataTimePoint,
                                                     next_dataTimePoint = next_dataTimePoint,
                                                     start_dt           = start_dt,
                                                     end_dt             = end_dt)
            else:
                raise ConsistencyException('No generator nor Operation?!')
            
  
            # Ok, append the operation/generator results to the labels and values
            Slot_data_labels.append(Slot_data_label_to_generate)
            Slot_data_vaues.append(result)
          
        #----------------------
        # Save results **
        #----------------------

        Slot_physicalData = self.Sensor.Points_type.data_type(labels = Slot_data_labels,
                                                              values = Slot_data_vaues)
        
        dataTimeSlot = self.Sensor.Slots_type(start    = TimePoint(t = start_dt),
                                              end      = TimePoint(t = end_dt),
                                              data     = Slot_physicalData,
                                              type     = timeSlotSpan,
                                              coverage = Slot_coverage)

        # Return results
        return dataTimeSlot
    

class DataTimeSlotsAggregator(Aggregator):
    '''Aggregate DataTimeSlots of a DataTimeSeries into a wider DataTimeSlot.
    The Aggregator is STATELESS'''
    
    # TODO: Merge me into a DataTimeSeriesAggregator, using the data type to understand how to aggregate? 

    pass


#-------------------------------------
# Aggregators Porcesses
#-------------------------------------

class DataTimeSeriesAggregatorProcess(object):
    '''A DataTimeSeriesAggregatorProcess run one or more DataTimePointsAggregator or DataTimeSlotsAggregator
    to generate a DataTimeSeries of DataTimeSlots. The destination DataTimeSlot drives the process (i.e. 
    aggregate in 15 minutes slots). The DataTimeSeriesAggregatorProcess is STATEFUL'''
    
    def __init__(self, timeSlotSpan, Sensor, data_to_aggregate):
        ''' Initiliaze the aggregator process, of a given timeSlotSpan.'''

        # Arguments
        self.timeSlotSpan            = timeSlotSpan
        self.Sensor                  = Sensor
        self.data_to_aggregate       = data_to_aggregate
        
        # Internal vars
        self.results_dataTimeSeries  = DataTimeSeries()
        self._aggregator             = None
        self.Aggregator              = None
        
        # Sanity checks
        if not self.data_to_aggregate:
            raise ConsistencyException("No data type set: got (got {})".format(self.data_to_aggregate))
        # Check for the DataTimePoint concept being extended (including combinations)
        elif issubclass(self.data_to_aggregate, DataPoint) and issubclass(self.data_to_aggregate, TimePoint):
            self.Aggregator = DataTimePointsAggregator
        # Check for the DataTimeSlot concept being extended (including combinations)
        elif issubclass(self.data_to_aggregate, DataSlot) and issubclass(self.data_to_aggregate, TimeSlot):
            self.Aggregator = DataTimeSlotsAggregator
        else:
            raise ConsistencyException("Un-handable data type: got no DataTimePoint, no DataTimeSlot and not None (got {})".format(self.data_to_aggregate)) 

    @property   
    def aggregator(self):
        
        # Instantiate the proper aggregator class if not already done
        if not self._aggregator:
            self._aggregator = self.Aggregator(Sensor=self.Sensor)
        return self._aggregator

    def start(self, dataTimeSeries, start_dt, end_dt, rounded=False, threaded=False):
        ''' Start the aggregator process. if start is not set, the first datapoint is used. If end is not set,
        once the process will provide the results until the last datapoint (useful for online processing)
        '''

        logger.info('Aggregation process started from {} to {} with a sensor of class {} on {}'.format(start_dt,
                                                                                                       end_dt,
                                                                                                       self.Sensor.__name__,
                                                                                                       dataTimeSeries))

        # For now start/end not set is not supported:
        if not start_dt or not end_dt:
            raise NotImplementedError('Empty start/end not yet implemented') 
        
        # Now start generating bins:
        print self.timeSlotSpan
        
        # Handle the rounded case
        if rounded:
            start_dt = self.timeSlotSpan.round_dt(start_dt) if start_dt else None
            end_dt   = self.timeSlotSpan.round_dt(end_dt) if end_dt   else None

        # Set some support varibales
        slot_start_dt      = None
        slot_end_dt        = None
        prev_dataTimePoint      = None
        filtered_dataTimeSeries = DataTimeSeries()

        # Ok, start running the aggregators in a streaming-fashion way,
        # so going trought all the data in the time series

        for dataTimePoint in dataTimeSeries:

            # Set start_dt if not already done
            if not start_dt:
                start_dt = self.timeSlotSpan.timeInterval.round_dt(dataTimePoint.dt) if rounded else dataTimePoint.dt
            
            if not slot_end_dt:   
                slot_end_dt = start_dt

            # First, check if we have some points to discard at the beginning       
            if dataTimePoint.dt < start_dt:
                # If we are here it means we are going data belonging to a previous slot
                # (probably just spare data loaded to have access to the prev_datapoint)  
                prev_dataTimePoint = dataTimePoint
                #logger.debug print 'dataTimePoint.dt (disc): ', dataTimePoint.dt
                continue

            # Same concept for the end (TODO: save only 'next data time point and move away from here..?')
            # TODO: also, handle end_dt if not set...
            if dataTimePoint.dt >= end_dt:
                #logger.debug print 'dataTimePoint.dt (disc): ', dataTimePoint.dt
                continue
              
            # Here we manage all the cases according to start/end, missing slots etc.
            # We have also to create empty slots at the beginning, at the end and in the middle.
            # An empty slot will have every required value (according to DataSlots_labels) set to None.
            # Even if the dataTimeSeries is completely empty, we have the DataSlots_labelsthatnks to
            # the Sensor object which is mandatory. And in future maybe even encapsulated in the time series.

            #----------------------------
            # Slots handling
            #----------------------------

            # The following procedure works in general for slots at the beginning and in the middle.
            # The approach is to detect if the current slot is "outdated" and spin a new one if so.

            if dataTimePoint.dt > slot_end_dt:
                # If the current slot is outdated, keep spinning new slots until the current
                # data point falls in one of them.
                
                # Read the following "while" more as an "if" which can also lead to spin multiple
                # slot if there are empty slots between the one being closed and the dataTimePoint.dt.
                # TODO: leave or remove the above if for code redability?
                
                while slot_end_dt < dataTimePoint.dt:
                    
                    # If we are in the pre-first slot, just silently spin a new slot:
                    if slot_start_dt is not None:
                                
                        logger.info('SlotStream: this slot (start={}, end={}) is closed, now aggregating it..'.format(slot_start_dt, slot_end_dt))

                        # Aggregate
                        aggregator_results = self.aggregator.aggregate(dataTimeSeries     = filtered_dataTimeSeries,
                                                                       start_dt           = slot_start_dt,
                                                                       end_dt             = slot_end_dt,
                                                                       timeSlotSpan       = self.timeSlotSpan,
                                                                       prev_dataTimePoint = prev_dataTimePoint,
                                                                       next_dataTimePoint = dataTimePoint.dt)
                        # .. and append results 
                        self.results_dataTimeSeries.append(aggregator_results)
                        
                    # Save this datapoint as the previous data time point
                    prev_dataTimePoint = dataTimePoint
                    
                    # Create a new slot
                    slot_start_dt = slot_end_dt
                    slot_end_dt   = slot_start_dt + self.timeSlotSpan
                    
                    # Create a new filtered_dataTimeSeries as part of the 'create a new slot' procedure
                    filtered_dataTimeSeries = DataTimeSeries()
                    
                    logger.info('SlotStream: Spawned a new slot (start={}, end={})'.format(slot_start_dt, slot_end_dt))
                    
       
       
            #----------------------------
            # Time series filtering
            #----------------------------
            
            filtered_dataTimeSeries.append(dataTimePoint)
            


        #----------------------------
        # Last slots(s)
        #----------------------------        
                
        # After going trough all the data time series, two things to do are remaining:
        
        # 1) Close the last slot
        
        #------------ START send to aggregation ------ 
        
        # Close the current slot and aggreagte it
        if filtered_dataTimeSeries:
  
            # Aggregate
            aggregator_results =  self.aggregator.aggregate(dataTimeSeries     = filtered_dataTimeSeries,
                                                            start_dt           = slot_start_dt,
                                                            end_dt             = slot_end_dt,
                                                            timeSlotSpan       = self.timeSlotSpan,
                                                            prev_dataTimePoint = prev_dataTimePoint,
                                                            next_dataTimePoint = dataTimePoint.dt)
            
            # .. and append results 
            self.results_dataTimeSeries.append(aggregator_results)


        # 2) Handle missing slots until the requested end (end_dt)
        
        # TODO...

 
    def get_results(self, until=None):
        if until:
            raise NotImplementedError('getting partial results is not yet supported')
         
        return self.results_dataTimeSeries




#-----------------------
# Utility functions
#-----------------------
def obtain_data_type(dataTimeSeries):
    # Are we processing a DataTimeSeries of Points or Slots?
    if dataTimeSeries.data_type == DataTimePoint:
        return DataTimePoint
        
    elif dataTimeSeries.data_type == DataTimeSlot:
        return DataTimeSlot
        
    elif dataTimeSeries.data_type == None:
        return None
    
    else:
        raise ConsistencyException("Got no DataTimePoint, no DataTimeSlot and not None {}".format(type(dataTimeSeries.data_type))) 

                    






# #-------------------------------------
# #    OLD follows
# #-------------------------------------





#             
#             
#                 # First, do we have to create missing slots between the previous slot_end and this slot_start?
#                 # This procedure works in general for slots at the beginning and in the middle.
#          
#                 if (prev_slot_end + self.timeSlotSpan.timeInterval) < dataTimePoint.dt:
#                     print 'Ok, here we need to generate 1 to n of missing slots'
#                     
#                 
#                 # Second, if the dataTimePoint.dt is after the current slot, we neet to create a new one
#                 if slot_end
#                 and (dataTimePoint.dt >)
#                 
#                 # Otherwise, we are in the correct slot.
#                 
#                 # Now, 
#                 
#                 slot_start
#             
#                 print 'dataTimePoint.dt: ', dataTimePoint.dt
#                 print 'slot_start   : ', slider_cur_dt
#                 
#                 # Is the first slot initialized?
#                 if not slot_start_dt:
#                     slot_start_dt = slider_cur_dt
#                 if not slot_end_dt:
#                     slot_end_dt = slot_start_dt + self.timeSlotSpan.timeInterval
#                 
#                 
#                 # Are we in the first slot?
#                 if dataTimePoint.dt < slot_end_dt
#             
# 
#                 # Start unrolling the timeSeries and the slots in the same time:
#                 
#             
#             # Now crate the slots 
#             while True:
#             
#                 slot_start_dt = slider_dt
#                 slot_end_dt   = slider_dt + self.timeSlotSpan.timeInterval
#                 
#                 # Here we are in a slot: start consuming the dataTimeSeries:
#                 
#                 # Fisrt, create a filtered dataTImeSeries
#                 filtered_dataTimeSeries = DataTimeSeries()
#                 
#                 # Now start start consuming the dataTimeSeries filtering it to obtain the data for this slot
#                 # TODO: optimize if not working with a streaming time series, just pass over the original one?
#                 
#                     
#                 if item.dt < slot_start_dt:
# 
#                     continue
#                 if item.dt >= slot_end_dt:
#                     # Stop filtering the dataTimeSeries and send it to the aggregation phase
#                     print filtered_dataTimeSeries
#                     break
#                 else:
#                     # Otherwise, keep adding items.
#                     print 'appending', item
#                     filtered_dataTimeSeries.append(item)
#         
#                 
#                 
#                 
#                 # Are we processing a DataTimeSeries of Points or Slots?
#                 if not data_type:
#                     obtain_data_type(filtered_dataTimeSeries)
#         
#                 # Which aggregator class to run then?
#                 if not aggregator:
#                     if data_type == DataTimePoint:
#                         aggregator = DataTimePointsAggregator(Sensor=self.Sensor)  
#                     elif data_type == DataTimeSlot:
#                         aggregator = DataTimeSlotsAggregator(Sensor=self.Sensor)
#                     elif data_type == None:
#                         pass
#                     else:
#                         raise ConsistencyException("Unhandable data tpe: got no DataTimePoint, no DataTimeSlot and not None (got {})".format(data_type)) 
#         
#         
#                 
#                 print ''
#                 print '-------------- SLOT START ---------------'
#                 print 'slot_start_dt', slot_start_dt
#                 print 'slot_end_dt', slot_end_dt
#                 print dataTimeSeries
#                 print '-----------------------------------------'
#                 print ''
#         
#                 sys.exit(0)
#                 if end_dt:
#                     if slot_end_dt >= slider_end_dt:
#                         break
#                 else:
#                     raise NotImplementedError('Not yet')
#                     # if time series ended, break
#                 
#                 
#                 # Set new slider value
#                 slider_dt = slot_end_dt
# 
# 
#         # for each Slot call the aggregator. For now just one.
#         for _ in range(1,2):
#             print dataTimeSeries
#             
#             # Select a subset of the time series:
#             
#             dataTimeSeries.filter(from_dt=start_dt, to_dt=end_dt)
#             
#             logger.info('Calling aggregator {}'.format(aggregator.__class__.__name__))
#             aggregator.aggregate(dataTimeSeries     = dataTimeSeries,
#                                  start_dt           = start_dt,
#                                  end_dt             = end_dt,
#                                  prev_dataTimePoint = None,
#                                  next_dataTimePoint = None)
#             








# See also componets for Ste, Series, etc. etc.!!

# 
# 
# #------------------------ BO -------------------------
# 
# class DataTimeSeriesAggregtor():
#     '''Operates on: DataTimeSeries, start_dt, end_dt'''
# 
#     def aggregate(self, dataTimeSeries, start_dt, end_dt, prev_dataTimePoint, next_dataTimePoint):
#         results = None
#         return results
# 
# class DataTimeSeriesAggregatorProcess():
#     '''Start the aggregation of a DataTimeSeries in a single Slot'''
#     pass
# 
# class DataTimeSeriesSlottedAggregatorProcess():
#     '''Start the aggregation of a DataTimeSeries in multiple Slots'''
# 
# 
# #-------------------------------------------------------
# 
# #class AggregatorProcess(object):
# 
# class SetAggregatorProcess(object):
#     '''A SetAggregator.'''
#     pass
# 
#     def aggregate(self):
#         pass
# 
# 
# class DataSetAggregatorProcess(SetAggregatorProcess):
#     '''A DataSetAggregator.'''
#     pass
# 
# class SeriesAggregatorProcess(object):
#     '''A SeriesAggregator.'''
#     pass
# 
# class DataSeriesAggregatorProcess(SeriesAggregatorProcess):
#     '''A DataSeriesAggregator.'''
#     pass
# 
# class DataTimeSeriesAggregator(DataSeriesAggregator):  
#     '''Aggregates DataTimeSeries of DataTimePoints or DataTimeSlots to provide a DataTimeSeries of DataTimeSlots'''
#     pass
# 
# 
# class Aggregator(object):
#     '''Aggregate data. Input: free. Output: free'''
#     pass
# 
# class PointsAggregator(Aggregator):
#     '''Aggregat points into a slot'''
#     
#     
# 
# class DataTimeSeriesAggregator
# 
# class DataTimePointsAggregator(Aggregator):
#     ''' Aggregate Points into slots'''
# 
# class DataTimeSlotsAggregator(object):
#     ''' Aggregate Slots into slots'''
# 
# 
# 
# 
# 
# ##################################################################
# # SlotAggregator -> TimeSlotAggregator
# ##################################################################
# 
# 
# class DataTimeSlotsAggregator():
#     ''' Aggregates DataTimeSeries of DataTimePoints or DataTimeSlots to privide a DataTimeSeries of DataTimeSlots'''
#     pass
# 
# 
# class DataTimeSlotsAggregator():
#     ''' Aggregates DataTimeSeries of DataTimePoints or DataTimeSlots to privide a DataTimeSeries of DataTimeSlots'''
#     pass
# 
# 
# 
# 
# # TODO: should be DataTimeSeries(TimeSeries, DataSeries)?
# class DataTimeSeriesAggregator(TimeSeriesAggregator): # -> DataTimeSeries
#     pass
# 
# 
# ##################################################################
# 
# 
# class SetAggregator(object):
#     '''Aggregates a Set of Points or Regions in whatever kind of output data'''
#     pass
#     
# class DataSetAggregator(SetAggregator):
#     '''Aggregates a DataSet of DataPoints or DataRegions of whatever kind of data in a DataRegion.
#     The DataSetAggregator computes also the coverage: how well is the result DataRegion covered by 
#     the DataPoints or DataRegions being aggregated.'''
#     pass
# 
# class DataTimeSeriesAggregator(DataSetAggregator):
#     '''Aggregates a TimeSeries of DataTimePoints or DataTimeSlots to give a TimeDataSlot with the results.
#     The results DataTimeSlot start and end are can be set or auto-detected given the input data.'''
#     pass
# 
# 
# 
# class AggregatorProcess(object):
#     pass
# 
# 
# 
# class AggregatorProcess(object):
#     '''This is a generic aggregator process, and it is stateful. It operates on a TimeSerie using an Aggregator and store
#     some results (numbers, string, dict, and of course TimeSerie). The results MUST be ann object of the class AggregatorResults,
#     as they must hav the __add__ implemented to be concatenated by the aggregator process.'''
# 
#     def __init__(self, aggregator, start_dt, end_dt):
#         ''' Initiliaze the aggregator process. if start is not set, the first datapoint is used. If end is not set,
#         once the process will provide the results until the last datapoint olny (useful for online processing)
#         the aggregator is an Aggregator object already instatitated'''
# 
# 
# 
# 
# 
# 
# 












